{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Quality Tables - Setup Notebook\n",
        "\n",
        "**Project:** Maven Fuzzy Factory E-Commerce Analytics  \n",
        "**Created:** November 20, 2025  \n",
        "**Purpose:** Create enhanced data quality log and summary tables with standardized schema\n",
        "\n",
        "---\n",
        "\n",
        "## Table Definitions\n",
        "\n",
        "### data_quality_log\n",
        "**Purpose:** Detailed validation results for each check performed  \n",
        "**Retention:** 90 days (configurable)  \n",
        "**Usage:** Root cause analysis, audit trail, failure investigation\n",
        "\n",
        "| Column | Type | Nullable | Description |\n",
        "|--------|------|----------|-------------|\n",
        "| run_id | STRING | No | Unique identifier for validation run (UUID) |\n",
        "| run_timestamp | TIMESTAMP | No | When validation was executed |\n",
        "| table_name | STRING | No | Source table being validated |\n",
        "| check_name | STRING | No | Name of validation check |\n",
        "| check_type | STRING | No | Category: completeness, uniqueness, validity |\n",
        "| column_name | STRING | Yes | Column(s) being validated |\n",
        "| passed | STRING | No | \"True\" or \"False\" |\n",
        "| invalid_count | INT | No | Number of invalid records found |\n",
        "| threshold | STRING | Yes | Expected threshold (e.g., \"0\", \">0\") |\n",
        "| message | STRING | Yes | Descriptive message about result |\n",
        "\n",
        "---\n",
        "\n",
        "### data_quality_summary\n",
        "**Purpose:** High-level quality metrics per validation run  \n",
        "**Retention:** 180 days (configurable)  \n",
        "**Usage:** Trending, dashboards, pipeline decision-making\n",
        "\n",
        "| Column | Type | Nullable | Description |\n",
        "|--------|------|----------|-------------|\n",
        "| run_id | STRING | No | Unique identifier (matches log) |\n",
        "| run_timestamp | TIMESTAMP | No | When validation was executed |\n",
        "| table_name | STRING | No | Source table being validated |\n",
        "| row_count | INT | No | Total rows in source table |\n",
        "| pk_duplicate_count | INT | No | Number of duplicate primary keys |\n",
        "| null_violations | INT | No | Total nulls in critical columns |\n",
        "| validation_checks_total | INT | No | Total validation checks performed |\n",
        "| validation_checks_passed | INT | No | Number of checks that passed |\n",
        "| quality_score | STRING | No | Percentage score (e.g., \"100.0\") |\n",
        "| overall_status | STRING | No | \"PASSED\" or \"FAILED\" |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop Existing Tables (If Present)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop existing tables to ensure clean slate\n",
        "spark.sql(\"DROP TABLE IF EXISTS data_quality_log\")\n",
        "spark.sql(\"DROP TABLE IF EXISTS data_quality_summary\")\n",
        "\n",
        "print(\"✓ Existing tables dropped (if they existed)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create data_quality_log Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define log table schema\n",
        "log_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"check_name\", StringType(), False),\n",
        "    StructField(\"check_type\", StringType(), False),\n",
        "    StructField(\"column_name\", StringType(), True),\n",
        "    StructField(\"passed\", StringType(), False),\n",
        "    StructField(\"invalid_count\", IntegerType(), False),\n",
        "    StructField(\"threshold\", StringType(), True),\n",
        "    StructField(\"message\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Create empty DataFrame\n",
        "empty_log_df = spark.createDataFrame([], log_schema)\n",
        "\n",
        "# Save as Delta table\n",
        "empty_log_df.write.mode(\"overwrite\").saveAsTable(\"data_quality_log\")\n",
        "\n",
        "print(\"✓ data_quality_log table created\")\n",
        "print(f\"  Columns: {len(log_schema.fields)}\")\n",
        "print(\"  Schema:\")\n",
        "spark.table(\"data_quality_log\").printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create data_quality_summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define summary table schema\n",
        "summary_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"row_count\", IntegerType(), False),\n",
        "    StructField(\"pk_duplicate_count\", IntegerType(), False),\n",
        "    StructField(\"null_violations\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_total\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_passed\", IntegerType(), False),\n",
        "    StructField(\"quality_score\", StringType(), False),\n",
        "    StructField(\"overall_status\", StringType(), False)\n",
        "])\n",
        "\n",
        "# Create empty DataFrame\n",
        "empty_summary_df = spark.createDataFrame([], summary_schema)\n",
        "\n",
        "# Save as Delta table\n",
        "empty_summary_df.write.mode(\"overwrite\").saveAsTable(\"data_quality_summary\")\n",
        "\n",
        "print(\"✓ data_quality_summary table created\")\n",
        "print(f\"  Columns: {len(summary_schema.fields)}\")\n",
        "print(\"  Schema:\")\n",
        "spark.table(\"data_quality_summary\").printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Table Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List quality tables\n",
        "print(\"Quality Tables in Lakehouse:\")\n",
        "spark.sql(\"SHOW TABLES LIKE 'data_quality*'\").show(truncate=False)\n",
        "\n",
        "# Verify row counts (should be 0)\n",
        "log_count = spark.table(\"data_quality_log\").count()\n",
        "summary_count = spark.table(\"data_quality_summary\").count()\n",
        "\n",
        "print(f\"\\nInitial Row Counts:\")\n",
        "print(f\"  data_quality_log: {log_count}\")\n",
        "print(f\"  data_quality_summary: {summary_count}\")\n",
        "\n",
        "if log_count == 0 and summary_count == 0:\n",
        "    print(\"\\n✓✓✓ SUCCESS: Quality tables created successfully!\")\n",
        "    print(\"\\nReady for validation notebooks to write data.\")\n",
        "else:\n",
        "    print(\"\\n⚠ WARNING: Tables contain data. Expected 0 rows.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Query Templates\n",
        "\n",
        "Use these queries after running validation notebooks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample queries for future use (commented out)\n",
        "\n",
        "sample_queries = \"\"\"\n",
        "-- Query 1: View all validation summary results\n",
        "SELECT \n",
        "    table_name,\n",
        "    run_timestamp,\n",
        "    quality_score,\n",
        "    overall_status,\n",
        "    validation_checks_passed,\n",
        "    validation_checks_total,\n",
        "    row_count\n",
        "FROM data_quality_summary\n",
        "ORDER BY run_timestamp DESC;\n",
        "\n",
        "-- Query 2: Find failed checks\n",
        "SELECT \n",
        "    table_name,\n",
        "    check_name,\n",
        "    column_name,\n",
        "    invalid_count,\n",
        "    threshold,\n",
        "    message\n",
        "FROM data_quality_log\n",
        "WHERE passed = 'False'\n",
        "ORDER BY table_name, check_name;\n",
        "\n",
        "-- Query 3: Quality score by table (most recent run)\n",
        "SELECT \n",
        "    table_name,\n",
        "    quality_score,\n",
        "    overall_status\n",
        "FROM (\n",
        "    SELECT \n",
        "        table_name,\n",
        "        quality_score,\n",
        "        overall_status,\n",
        "        ROW_NUMBER() OVER (PARTITION BY table_name ORDER BY run_timestamp DESC) as rn\n",
        "    FROM data_quality_summary\n",
        ") ranked\n",
        "WHERE rn = 1\n",
        "ORDER BY table_name;\n",
        "\"\"\"\n",
        "\n",
        "print(\"Sample Query Templates:\")\n",
        "print(sample_queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Setup Complete ✓\n",
        "\n",
        "**Next Steps:**\n",
        "1. Run validation notebooks for each staging table\n",
        "2. Review quality scores in `data_quality_summary`\n",
        "3. Investigate any failures in `data_quality_log`\n",
        "4. Proceed to transformation phase once all tables pass\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}