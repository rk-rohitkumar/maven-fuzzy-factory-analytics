{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Quality Validation - Pageviews Table\n",
        "\n",
        "**Table:** `stg_pageviews`  \n",
        "**Project:** Maven Fuzzy Factory E-Commerce Analytics  \n",
        "**Created:** November 20, 2025  \n",
        "**Purpose:** Validate data quality for website pageviews staging table\n",
        "\n",
        "---\n",
        "\n",
        "## Validation Scope\n",
        "\n",
        "**Primary Key:** website_pageview_id  \n",
        "**Foreign Keys:** website_session_id  \n",
        "**Critical Fields:** created_at, pageview_url  \n",
        "**Expected Row Count Range:** 10,000 - 5,000,000\n",
        "\n",
        "**Validation Checks:**\n",
        "- Row count within expected range\n",
        "- Primary key uniqueness\n",
        "- Null checks on critical columns\n",
        "- Data type validation\n",
        "- Positive integer validation for IDs\n",
        "- No future dates\n",
        "- Valid URL format (non-empty strings)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import IntegerType, StructType, StructField, StringType, TimestampType\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "\n",
        "# Restore Python built-in sum (prevent PySpark function shadowing)\n",
        "del sum\n",
        "\n",
        "# Configuration\n",
        "SOURCE_TABLE = \"stg_pageviews\"\n",
        "PK_COLUMN = \"website_pageview_id\"\n",
        "QUALITY_LOG_TABLE = \"data_quality_log\"\n",
        "QUALITY_SUMMARY_TABLE = \"data_quality_summary\"\n",
        "\n",
        "# Quality thresholds\n",
        "MAX_DUPLICATE_PCT = 1.0  # Max 1% duplicates allowed\n",
        "MIN_ROW_COUNT = 10000\n",
        "MAX_ROW_COUNT = 5000000\n",
        "\n",
        "# Validation run metadata\n",
        "RUN_ID = str(uuid.uuid4())\n",
        "RUN_TIMESTAMP = datetime.now()\n",
        "\n",
        "print(f\"Validation Run ID: {RUN_ID}\")\n",
        "print(f\"Run Timestamp: {RUN_TIMESTAMP}\")\n",
        "print(f\"Source Table: {SOURCE_TABLE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Source Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load staging table\n",
        "df = spark.read.table(SOURCE_TABLE)\n",
        "\n",
        "print(f\"Total Rows: {df.count():,}\")\n",
        "print(f\"Total Columns: {len(df.columns)}\")\n",
        "print(\"\\nSchema:\")\n",
        "df.printSchema()\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample Data:\")\n",
        "df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "total_rows = df.count()\n",
        "distinct_pageviews = df.select(PK_COLUMN).distinct().count()\n",
        "distinct_sessions = df.select(\"website_session_id\").distinct().count()\n",
        "\n",
        "# Date range\n",
        "date_stats = df.select(\n",
        "    min(col(\"created_at\")).alias(\"min_date\"),\n",
        "    max(col(\"created_at\")).alias(\"max_date\")\n",
        ").collect()[0]\n",
        "\n",
        "# URL patterns\n",
        "url_stats = df.groupBy(\"pageview_url\").count().orderBy(desc(\"count\"))\n",
        "\n",
        "print(f\"Total Rows: {total_rows:,}\")\n",
        "print(f\"Distinct Pageviews: {distinct_pageviews:,}\")\n",
        "print(f\"Distinct Sessions: {distinct_sessions:,}\")\n",
        "print(f\"Duplicate Pageviews: {total_rows - distinct_pageviews:,} ({((total_rows - distinct_pageviews) / total_rows * 100):.2f}%)\")\n",
        "print(f\"Date Range: {date_stats['min_date']} to {date_stats['max_date']}\")\n",
        "print(f\"\\nTop 10 Most Viewed Pages:\")\n",
        "url_stats.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Validation Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize validation results storage\n",
        "validation_results = []\n",
        "\n",
        "def add_validation_result(check_name, check_type, column_name, passed, invalid_count, threshold, message):\n",
        "    \"\"\"Helper function to store validation results\"\"\"\n",
        "    validation_results.append({\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"run_timestamp\": RUN_TIMESTAMP,\n",
        "        \"table_name\": SOURCE_TABLE,\n",
        "        \"check_name\": check_name,\n",
        "        \"check_type\": check_type,\n",
        "        \"column_name\": column_name,\n",
        "        \"passed\": \"True\" if passed else \"False\",\n",
        "        \"invalid_count\": invalid_count,\n",
        "        \"threshold\": threshold,\n",
        "        \"message\": message\n",
        "    })\n",
        "    \n",
        "    status = \"✓ PASSED\" if passed else \"✗ FAILED\"\n",
        "    print(f\"{status} - {check_name}: {message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 1: Row count within expected range\n",
        "row_count_valid = MIN_ROW_COUNT <= total_rows <= MAX_ROW_COUNT\n",
        "add_validation_result(\n",
        "    check_name=\"Row Count Range\",\n",
        "    check_type=\"completeness\",\n",
        "    column_name=\"*\",\n",
        "    passed=row_count_valid,\n",
        "    invalid_count=0 if row_count_valid else total_rows,\n",
        "    threshold=f\"{MIN_ROW_COUNT}-{MAX_ROW_COUNT}\",\n",
        "    message=f\"Row count {total_rows:,} is {'within' if row_count_valid else 'outside'} expected range\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 2: Primary key uniqueness\n",
        "duplicate_count = total_rows - distinct_pageviews\n",
        "duplicate_pct = (duplicate_count / total_rows * 100) if total_rows > 0 else 0\n",
        "pk_valid = duplicate_pct <= MAX_DUPLICATE_PCT\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Primary Key Uniqueness\",\n",
        "    check_type=\"uniqueness\",\n",
        "    column_name=PK_COLUMN,\n",
        "    passed=pk_valid,\n",
        "    invalid_count=duplicate_count,\n",
        "    threshold=f\"<={MAX_DUPLICATE_PCT}%\",\n",
        "    message=f\"Found {duplicate_count:,} duplicates ({duplicate_pct:.2f}%)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 3: Null value checks for critical columns\n",
        "critical_columns = [PK_COLUMN, \"website_session_id\", \"created_at\", \"pageview_url\"]\n",
        "\n",
        "for col_name in critical_columns:\n",
        "    null_count = df.filter(col(col_name).isNull()).count()\n",
        "    null_valid = null_count == 0\n",
        "    \n",
        "    add_validation_result(\n",
        "        check_name=f\"Null Check - {col_name}\",\n",
        "        check_type=\"completeness\",\n",
        "        column_name=col_name,\n",
        "        passed=null_valid,\n",
        "        invalid_count=null_count,\n",
        "        threshold=\"0\",\n",
        "        message=f\"Found {null_count:,} null values\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 4: Positive integer validation\n",
        "negative_pageview_ids = df.filter(col(PK_COLUMN) <= 0).count()\n",
        "negative_session_ids = df.filter(col(\"website_session_id\") <= 0).count()\n",
        "\n",
        "pageview_id_valid = negative_pageview_ids == 0\n",
        "session_id_valid = negative_session_ids == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Positive Integer - pageview_id\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=PK_COLUMN,\n",
        "    passed=pageview_id_valid,\n",
        "    invalid_count=negative_pageview_ids,\n",
        "    threshold=\">0\",\n",
        "    message=f\"Found {negative_pageview_ids:,} non-positive IDs\"\n",
        ")\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Positive Integer - session_id\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=\"website_session_id\",\n",
        "    passed=session_id_valid,\n",
        "    invalid_count=negative_session_ids,\n",
        "    threshold=\">0\",\n",
        "    message=f\"Found {negative_session_ids:,} non-positive IDs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 5: No future dates\n",
        "current_timestamp = datetime.now()\n",
        "future_dates = df.filter(col(\"created_at\") > lit(current_timestamp)).count()\n",
        "date_valid = future_dates == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"No Future Dates\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=\"created_at\",\n",
        "    passed=date_valid,\n",
        "    invalid_count=future_dates,\n",
        "    threshold=\"<= current_date\",\n",
        "    message=f\"Found {future_dates:,} future dates\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 6: Valid URL format (non-empty strings)\n",
        "invalid_urls = df.filter(\n",
        "    (col(\"pageview_url\").isNull()) | \n",
        "    (trim(col(\"pageview_url\")) == \"\")\n",
        ").count()\n",
        "url_valid = invalid_urls == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Valid URL Format\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=\"pageview_url\",\n",
        "    passed=url_valid,\n",
        "    invalid_count=invalid_urls,\n",
        "    threshold=\"non-empty string\",\n",
        "    message=f\"Found {invalid_urls:,} empty/null URLs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Calculate Quality Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate overall quality score\n",
        "total_checks = len(validation_results)\n",
        "passed_checks = sum([1 for r in validation_results if r[\"passed\"] == \"True\"])\n",
        "quality_score = (passed_checks / total_checks * 100) if total_checks > 0 else 0\n",
        "overall_status = \"PASSED\" if quality_score == 100 else \"FAILED\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"QUALITY SCORE: {quality_score:.1f}%\")\n",
        "print(f\"CHECKS PASSED: {passed_checks}/{total_checks}\")\n",
        "print(f\"OVERALL STATUS: {overall_status}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Persist Results to Quality Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create validation log DataFrame with exact schema matching table\n",
        "log_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"check_name\", StringType(), False),\n",
        "    StructField(\"check_type\", StringType(), False),\n",
        "    StructField(\"column_name\", StringType(), True),\n",
        "    StructField(\"passed\", StringType(), False),\n",
        "    StructField(\"invalid_count\", IntegerType(), False),\n",
        "    StructField(\"threshold\", StringType(), True),\n",
        "    StructField(\"message\", StringType(), True)\n",
        "])\n",
        "\n",
        "validation_log_df = spark.createDataFrame(validation_results, schema=log_schema)\n",
        "\n",
        "# Write to quality log table (append mode)\n",
        "validation_log_df.write.mode(\"append\").saveAsTable(QUALITY_LOG_TABLE)\n",
        "\n",
        "print(f\"✓ Validation results written to {QUALITY_LOG_TABLE}\")\n",
        "print(f\"  Records written: {len(validation_results)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Persist Summary to Quality Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate null violations\n",
        "null_violations = sum([r[\"invalid_count\"] for r in validation_results if r[\"check_type\"] == \"completeness\" and \"Null Check\" in r[\"check_name\"]])\n",
        "\n",
        "# Create summary record\n",
        "summary_data = [{\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"run_timestamp\": RUN_TIMESTAMP,\n",
        "    \"table_name\": SOURCE_TABLE,\n",
        "    \"row_count\": total_rows,\n",
        "    \"pk_duplicate_count\": duplicate_count,\n",
        "    \"null_violations\": null_violations,\n",
        "    \"validation_checks_total\": total_checks,\n",
        "    \"validation_checks_passed\": passed_checks,\n",
        "    \"quality_score\": f\"{quality_score:.1f}\",\n",
        "    \"overall_status\": overall_status\n",
        "}]\n",
        "\n",
        "summary_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"row_count\", IntegerType(), False),\n",
        "    StructField(\"pk_duplicate_count\", IntegerType(), False),\n",
        "    StructField(\"null_violations\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_total\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_passed\", IntegerType(), False),\n",
        "    StructField(\"quality_score\", StringType(), False),\n",
        "    StructField(\"overall_status\", StringType(), False)\n",
        "])\n",
        "\n",
        "summary_df = spark.createDataFrame(summary_data, schema=summary_schema)\n",
        "\n",
        "# Write to summary table (append mode)\n",
        "summary_df.write.mode(\"append\").saveAsTable(QUALITY_SUMMARY_TABLE)\n",
        "\n",
        "print(f\"✓ Summary written to {QUALITY_SUMMARY_TABLE}\")\n",
        "print(f\"\\nValidation Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Verification - Query Persisted Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query and display persisted log results for this run\n",
        "print(\"Validation Log Records:\")\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT check_name, check_type, column_name, passed, invalid_count, message\n",
        "    FROM {QUALITY_LOG_TABLE}\n",
        "    WHERE run_id = '{RUN_ID}'\n",
        "    ORDER BY check_name\n",
        "\"\"\").show(truncate=False)\n",
        "\n",
        "# Query and display summary\n",
        "print(\"\\nQuality Summary:\")\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT table_name, row_count, pk_duplicate_count, null_violations,\n",
        "           validation_checks_passed, validation_checks_total, \n",
        "           quality_score, overall_status\n",
        "    FROM {QUALITY_SUMMARY_TABLE}\n",
        "    WHERE run_id = '{RUN_ID}'\n",
        "\"\"\").show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}