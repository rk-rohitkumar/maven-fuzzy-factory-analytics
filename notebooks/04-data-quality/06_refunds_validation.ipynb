{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Quality Validation - Refunds Table\n",
        "\n",
        "**Table:** `stg_refunds`  \n",
        "**Project:** Maven Fuzzy Factory E-Commerce Analytics  \n",
        "**Created:** November 20, 2025  \n",
        "**Purpose:** Validate data quality for refunds (order_item_refunds) staging table\n",
        "\n",
        "---\n",
        "\n",
        "## Validation Scope\n",
        "\n",
        "**Primary Key:** order_item_refund_id  \n",
        "**Foreign Keys:** order_item_id, order_id  \n",
        "**Critical Fields:** created_at, refund_amount_usd  \n",
        "**Expected Row Count Range:** 0 - 50,000\n",
        "\n",
        "**Validation Checks:**\n",
        "- Row count within expected range\n",
        "- Primary key uniqueness\n",
        "- Null checks on critical columns (if data exists)\n",
        "- Data type validation\n",
        "- Positive values for IDs and refund amounts\n",
        "- No future dates\n",
        "- Empty table handling (refunds may be zero)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import IntegerType, StructType, StructField, StringType, TimestampType\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "\n",
        "# Restore Python built-in sum (prevent PySpark function shadowing)\n",
        "del sum\n",
        "\n",
        "# Configuration\n",
        "SOURCE_TABLE = \"stg_refunds\"\n",
        "PK_COLUMN = \"order_item_refund_id\"\n",
        "QUALITY_LOG_TABLE = \"data_quality_log\"\n",
        "QUALITY_SUMMARY_TABLE = \"data_quality_summary\"\n",
        "\n",
        "# Quality thresholds\n",
        "MAX_DUPLICATE_PCT = 1.0  # Max 1% duplicates allowed\n",
        "MIN_ROW_COUNT = 0  # Refunds may be zero if no returns\n",
        "MAX_ROW_COUNT = 50000\n",
        "\n",
        "# Validation run metadata\n",
        "RUN_ID = str(uuid.uuid4())\n",
        "RUN_TIMESTAMP = datetime.now()\n",
        "\n",
        "print(f\"Validation Run ID: {RUN_ID}\")\n",
        "print(f\"Run Timestamp: {RUN_TIMESTAMP}\")\n",
        "print(f\"Source Table: {SOURCE_TABLE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Source Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load staging table\n",
        "df = spark.read.table(SOURCE_TABLE)\n",
        "\n",
        "print(f\"Total Rows: {df.count():,}\")\n",
        "print(f\"Total Columns: {len(df.columns)}\")\n",
        "print(\"\\nSchema:\")\n",
        "df.printSchema()\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample Data:\")\n",
        "df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "total_rows = df.count()\n",
        "\n",
        "# Handle case where table might be empty\n",
        "if total_rows > 0:\n",
        "    distinct_refunds = df.select(PK_COLUMN).distinct().count()\n",
        "    distinct_items = df.select(\"order_item_id\").distinct().count()\n",
        "    distinct_orders = df.select(\"order_id\").distinct().count()\n",
        "    \n",
        "    # Date range\n",
        "    date_stats = df.select(\n",
        "        min(col(\"created_at\")).alias(\"min_date\"),\n",
        "        max(col(\"created_at\")).alias(\"max_date\")\n",
        "    ).collect()[0]\n",
        "    \n",
        "    # Refund amount statistics\n",
        "    amount_stats = df.select(\n",
        "        sum(col(\"refund_amount_usd\")).alias(\"total_refunds\"),\n",
        "        avg(col(\"refund_amount_usd\")).alias(\"avg_refund\"),\n",
        "        min(col(\"refund_amount_usd\")).alias(\"min_refund\"),\n",
        "        max(col(\"refund_amount_usd\")).alias(\"max_refund\")\n",
        "    ).collect()[0]\n",
        "    \n",
        "    # Refund frequency by order\n",
        "    refunds_per_order = df.groupBy(\"order_id\").count().agg(\n",
        "        avg(col(\"count\")).alias(\"avg_refunds_per_order\"),\n",
        "        max(col(\"count\")).alias(\"max_refunds_per_order\")\n",
        "    ).collect()[0]\n",
        "    \n",
        "    print(f\"Total Rows: {total_rows:,}\")\n",
        "    print(f\"Distinct Refunds: {distinct_refunds:,}\")\n",
        "    print(f\"Distinct Order Items Refunded: {distinct_items:,}\")\n",
        "    print(f\"Distinct Orders with Refunds: {distinct_orders:,}\")\n",
        "    print(f\"Duplicate Refunds: {total_rows - distinct_refunds:,} ({((total_rows - distinct_refunds) / total_rows * 100):.2f}%)\")\n",
        "    print(f\"Date Range: {date_stats['min_date']} to {date_stats['max_date']}\")\n",
        "    print(f\"\\nRefund Amount Statistics:\")\n",
        "    print(f\"  Total Refunds: ${amount_stats['total_refunds']:,.2f}\")\n",
        "    print(f\"  Average Refund: ${amount_stats['avg_refund']:.2f}\")\n",
        "    print(f\"  Min Refund: ${amount_stats['min_refund']:.2f}\")\n",
        "    print(f\"  Max Refund: ${amount_stats['max_refund']:.2f}\")\n",
        "    print(f\"\\nRefund Frequency:\")\n",
        "    print(f\"  Avg Refunds per Order: {refunds_per_order['avg_refunds_per_order']:.2f}\")\n",
        "    print(f\"  Max Refunds per Order: {refunds_per_order['max_refunds_per_order']}\")\n",
        "else:\n",
        "    print(\"Table is empty - no refunds recorded\")\n",
        "    distinct_refunds = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Validation Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize validation results storage\n",
        "validation_results = []\n",
        "\n",
        "def add_validation_result(check_name, check_type, column_name, passed, invalid_count, threshold, message):\n",
        "    \"\"\"Helper function to store validation results\"\"\"\n",
        "    validation_results.append({\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"run_timestamp\": RUN_TIMESTAMP,\n",
        "        \"table_name\": SOURCE_TABLE,\n",
        "        \"check_name\": check_name,\n",
        "        \"check_type\": check_type,\n",
        "        \"column_name\": column_name,\n",
        "        \"passed\": \"True\" if passed else \"False\",\n",
        "        \"invalid_count\": invalid_count,\n",
        "        \"threshold\": threshold,\n",
        "        \"message\": message\n",
        "    })\n",
        "    \n",
        "    status = \"✓ PASSED\" if passed else \"✗ FAILED\"\n",
        "    print(f\"{status} - {check_name}: {message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 1: Row count within expected range\n",
        "row_count_valid = MIN_ROW_COUNT <= total_rows <= MAX_ROW_COUNT\n",
        "add_validation_result(\n",
        "    check_name=\"Row Count Range\",\n",
        "    check_type=\"completeness\",\n",
        "    column_name=\"*\",\n",
        "    passed=row_count_valid,\n",
        "    invalid_count=0 if row_count_valid else total_rows,\n",
        "    threshold=f\"{MIN_ROW_COUNT}-{MAX_ROW_COUNT}\",\n",
        "    message=f\"Row count {total_rows:,} is {'within' if row_count_valid else 'outside'} expected range\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Only run remaining checks if table has data\n",
        "if total_rows > 0:\n",
        "    # Check 2: Primary key uniqueness\n",
        "    duplicate_count = total_rows - distinct_refunds\n",
        "    duplicate_pct = (duplicate_count / total_rows * 100) if total_rows > 0 else 0\n",
        "    pk_valid = duplicate_pct <= MAX_DUPLICATE_PCT\n",
        "    \n",
        "    add_validation_result(\n",
        "        check_name=\"Primary Key Uniqueness\",\n",
        "        check_type=\"uniqueness\",\n",
        "        column_name=PK_COLUMN,\n",
        "        passed=pk_valid,\n",
        "        invalid_count=duplicate_count,\n",
        "        threshold=f\"<={MAX_DUPLICATE_PCT}%\",\n",
        "        message=f\"Found {duplicate_count:,} duplicates ({duplicate_pct:.2f}%)\"\n",
        "    )\n",
        "else:\n",
        "    duplicate_count = 0\n",
        "    add_validation_result(\n",
        "        check_name=\"Primary Key Uniqueness\",\n",
        "        check_type=\"uniqueness\",\n",
        "        column_name=PK_COLUMN,\n",
        "        passed=True,\n",
        "        invalid_count=0,\n",
        "        threshold=f\"<={MAX_DUPLICATE_PCT}%\",\n",
        "        message=\"No data to validate (table empty)\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 3: Null value checks for critical columns (only if data exists)\n",
        "if total_rows > 0:\n",
        "    critical_columns = [PK_COLUMN, \"created_at\", \"order_item_id\", \"order_id\", \"refund_amount_usd\"]\n",
        "    \n",
        "    for col_name in critical_columns:\n",
        "        null_count = df.filter(col(col_name).isNull()).count()\n",
        "        null_valid = null_count == 0\n",
        "        \n",
        "        add_validation_result(\n",
        "            check_name=f\"Null Check - {col_name}\",\n",
        "            check_type=\"completeness\",\n",
        "            column_name=col_name,\n",
        "            passed=null_valid,\n",
        "            invalid_count=null_count,\n",
        "            threshold=\"0\",\n",
        "            message=f\"Found {null_count:,} null values\"\n",
        "        )\n",
        "else:\n",
        "    print(\"Skipping null checks - table is empty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 4: Positive values for IDs and amounts (only if data exists)\n",
        "if total_rows > 0:\n",
        "    numeric_checks = {\n",
        "        PK_COLUMN: \">0\",\n",
        "        \"order_item_id\": \">0\",\n",
        "        \"order_id\": \">0\",\n",
        "        \"refund_amount_usd\": \">0\"\n",
        "    }\n",
        "    \n",
        "    for col_name, threshold in numeric_checks.items():\n",
        "        invalid_count = df.filter(col(col_name) <= 0).count()\n",
        "        valid = invalid_count == 0\n",
        "        \n",
        "        add_validation_result(\n",
        "            check_name=f\"Positive Value - {col_name}\",\n",
        "            check_type=\"validity\",\n",
        "            column_name=col_name,\n",
        "            passed=valid,\n",
        "            invalid_count=invalid_count,\n",
        "            threshold=threshold,\n",
        "            message=f\"Found {invalid_count:,} non-positive values\"\n",
        "        )\n",
        "else:\n",
        "    print(\"Skipping positive value checks - table is empty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 5: No future dates (only if data exists)\n",
        "if total_rows > 0:\n",
        "    current_timestamp = datetime.now()\n",
        "    future_dates = df.filter(col(\"created_at\") > lit(current_timestamp)).count()\n",
        "    date_valid = future_dates == 0\n",
        "    \n",
        "    add_validation_result(\n",
        "        check_name=\"No Future Dates\",\n",
        "        check_type=\"validity\",\n",
        "        column_name=\"created_at\",\n",
        "        passed=date_valid,\n",
        "        invalid_count=future_dates,\n",
        "        threshold=\"<= current_date\",\n",
        "        message=f\"Found {future_dates:,} future dates\"\n",
        "    )\n",
        "else:\n",
        "    print(\"Skipping date checks - table is empty\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Calculate Quality Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate overall quality score\n",
        "total_checks = len(validation_results)\n",
        "passed_checks = sum([1 for r in validation_results if r[\"passed\"] == \"True\"])\n",
        "quality_score = (passed_checks / total_checks * 100) if total_checks > 0 else 0\n",
        "overall_status = \"PASSED\" if quality_score == 100 else \"FAILED\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"QUALITY SCORE: {quality_score:.1f}%\")\n",
        "print(f\"CHECKS PASSED: {passed_checks}/{total_checks}\")\n",
        "print(f\"OVERALL STATUS: {overall_status}\")\n",
        "if total_rows == 0:\n",
        "    print(\"NOTE: Table is empty - minimal checks performed\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Persist Results to Quality Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create validation log DataFrame with exact schema matching table\n",
        "log_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"check_name\", StringType(), False),\n",
        "    StructField(\"check_type\", StringType(), False),\n",
        "    StructField(\"column_name\", StringType(), True),\n",
        "    StructField(\"passed\", StringType(), False),\n",
        "    StructField(\"invalid_count\", IntegerType(), False),\n",
        "    StructField(\"threshold\", StringType(), True),\n",
        "    StructField(\"message\", StringType(), True)\n",
        "])\n",
        "\n",
        "validation_log_df = spark.createDataFrame(validation_results, schema=log_schema)\n",
        "\n",
        "# Write to quality log table (append mode)\n",
        "validation_log_df.write.mode(\"append\").saveAsTable(QUALITY_LOG_TABLE)\n",
        "\n",
        "print(f\"✓ Validation results written to {QUALITY_LOG_TABLE}\")\n",
        "print(f\"  Records written: {len(validation_results)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Persist Summary to Quality Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate null violations\n",
        "null_violations = sum([r[\"invalid_count\"] for r in validation_results if r[\"check_type\"] == \"completeness\" and \"Null Check\" in r[\"check_name\"]])\n",
        "\n",
        "# Create summary record\n",
        "summary_data = [{\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"run_timestamp\": RUN_TIMESTAMP,\n",
        "    \"table_name\": SOURCE_TABLE,\n",
        "    \"row_count\": total_rows,\n",
        "    \"pk_duplicate_count\": duplicate_count,\n",
        "    \"null_violations\": null_violations,\n",
        "    \"validation_checks_total\": total_checks,\n",
        "    \"validation_checks_passed\": passed_checks,\n",
        "    \"quality_score\": f\"{quality_score:.1f}\",\n",
        "    \"overall_status\": overall_status\n",
        "}]\n",
        "\n",
        "summary_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"row_count\", IntegerType(), False),\n",
        "    StructField(\"pk_duplicate_count\", IntegerType(), False),\n",
        "    StructField(\"null_violations\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_total\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_passed\", IntegerType(), False),\n",
        "    StructField(\"quality_score\", StringType(), False),\n",
        "    StructField(\"overall_status\", StringType(), False)\n",
        "])\n",
        "\n",
        "summary_df = spark.createDataFrame(summary_data, schema=summary_schema)\n",
        "\n",
        "# Write to summary table (append mode)\n",
        "summary_df.write.mode(\"append\").saveAsTable(QUALITY_SUMMARY_TABLE)\n",
        "\n",
        "print(f\"✓ Summary written to {QUALITY_SUMMARY_TABLE}\")\n",
        "print(f\"\\nValidation Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Verification - Query Persisted Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query and display persisted log results for this run\n",
        "print(\"Validation Log Records:\")\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT check_name, check_type, column_name, passed, invalid_count, message\n",
        "    FROM {QUALITY_LOG_TABLE}\n",
        "    WHERE run_id = '{RUN_ID}'\n",
        "    ORDER BY check_name\n",
        "\"\"\").show(truncate=False)\n",
        "\n",
        "# Query and display summary\n",
        "print(\"\\nQuality Summary:\")\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT table_name, row_count, pk_duplicate_count, null_violations,\n",
        "           validation_checks_passed, validation_checks_total, \n",
        "           quality_score, overall_status\n",
        "    FROM {QUALITY_SUMMARY_TABLE}\n",
        "    WHERE run_id = '{RUN_ID}'\n",
        "\"\"\").show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}