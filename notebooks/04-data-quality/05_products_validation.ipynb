{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Quality Validation - Products Table\n",
        "\n",
        "**Table:** `stg_products`  \n",
        "**Project:** Maven Fuzzy Factory E-Commerce Analytics  \n",
        "**Created:** November 20, 2025  \n",
        "**Purpose:** Validate data quality for products staging table\n",
        "\n",
        "---\n",
        "\n",
        "## Validation Scope\n",
        "\n",
        "**Primary Key:** product_id  \n",
        "**Foreign Keys:** None (master data table)  \n",
        "**Critical Fields:** created_at, product_name  \n",
        "**Expected Row Count Range:** 1 - 100\n",
        "\n",
        "**Validation Checks:**\n",
        "- Row count within expected range\n",
        "- Primary key uniqueness (0% duplicates for master data)\n",
        "- Null checks on critical columns\n",
        "- Data type validation\n",
        "- Positive integer validation for IDs\n",
        "- No future dates\n",
        "- Valid product name format\n",
        "- Product name uniqueness\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import IntegerType, StructType, StructField, StringType, TimestampType\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "\n",
        "# Restore Python built-in sum (prevent PySpark function shadowing)\n",
        "del sum\n",
        "\n",
        "# Configuration\n",
        "SOURCE_TABLE = \"stg_products\"\n",
        "PK_COLUMN = \"product_id\"\n",
        "QUALITY_LOG_TABLE = \"data_quality_log\"\n",
        "QUALITY_SUMMARY_TABLE = \"data_quality_summary\"\n",
        "\n",
        "# Quality thresholds\n",
        "MAX_DUPLICATE_PCT = 0.0  # 0% duplicates allowed for master data\n",
        "MIN_ROW_COUNT = 1\n",
        "MAX_ROW_COUNT = 100\n",
        "\n",
        "# Validation run metadata\n",
        "RUN_ID = str(uuid.uuid4())\n",
        "RUN_TIMESTAMP = datetime.now()\n",
        "\n",
        "print(f\"Validation Run ID: {RUN_ID}\")\n",
        "print(f\"Run Timestamp: {RUN_TIMESTAMP}\")\n",
        "print(f\"Source Table: {SOURCE_TABLE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Source Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load staging table\n",
        "df = spark.read.table(SOURCE_TABLE)\n",
        "\n",
        "print(f\"Total Rows: {df.count():,}\")\n",
        "print(f\"Total Columns: {len(df.columns)}\")\n",
        "print(\"\\nSchema:\")\n",
        "df.printSchema()\n",
        "\n",
        "# Display all products (likely small dataset)\n",
        "print(\"\\nAll Products:\")\n",
        "df.orderBy(\"product_id\").show(100, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "total_rows = df.count()\n",
        "distinct_products = df.select(PK_COLUMN).distinct().count()\n",
        "distinct_names = df.select(\"product_name\").distinct().count()\n",
        "\n",
        "# Date range\n",
        "date_stats = df.select(\n",
        "    min(col(\"created_at\")).alias(\"min_date\"),\n",
        "    max(col(\"created_at\")).alias(\"max_date\")\n",
        ").collect()[0]\n",
        "\n",
        "# Product name analysis\n",
        "name_stats = df.select(\n",
        "    length(col(\"product_name\")).alias(\"name_length\")\n",
        ").agg(\n",
        "    min(col(\"name_length\")).alias(\"min_name_length\"),\n",
        "    max(col(\"name_length\")).alias(\"max_name_length\"),\n",
        "    avg(col(\"name_length\")).alias(\"avg_name_length\")\n",
        ").collect()[0]\n",
        "\n",
        "print(f\"Total Rows: {total_rows:,}\")\n",
        "print(f\"Distinct Products: {distinct_products:,}\")\n",
        "print(f\"Distinct Product Names: {distinct_names:,}\")\n",
        "print(f\"Duplicate Products: {total_rows - distinct_products:,} ({((total_rows - distinct_products) / total_rows * 100) if total_rows > 0 else 0:.2f}%)\")\n",
        "print(f\"Date Range: {date_stats['min_date']} to {date_stats['max_date']}\")\n",
        "print(f\"\\nProduct Name Statistics:\")\n",
        "print(f\"  Min Name Length: {name_stats['min_name_length']} characters\")\n",
        "print(f\"  Max Name Length: {name_stats['max_name_length']} characters\")\n",
        "print(f\"  Avg Name Length: {name_stats['avg_name_length']:.1f} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Validation Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize validation results storage\n",
        "validation_results = []\n",
        "\n",
        "def add_validation_result(check_name, check_type, column_name, passed, invalid_count, threshold, message):\n",
        "    \"\"\"Helper function to store validation results\"\"\"\n",
        "    validation_results.append({\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"run_timestamp\": RUN_TIMESTAMP,\n",
        "        \"table_name\": SOURCE_TABLE,\n",
        "        \"check_name\": check_name,\n",
        "        \"check_type\": check_type,\n",
        "        \"column_name\": column_name,\n",
        "        \"passed\": \"True\" if passed else \"False\",\n",
        "        \"invalid_count\": invalid_count,\n",
        "        \"threshold\": threshold,\n",
        "        \"message\": message\n",
        "    })\n",
        "    \n",
        "    status = \"✓ PASSED\" if passed else \"✗ FAILED\"\n",
        "    print(f\"{status} - {check_name}: {message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 1: Row count within expected range\n",
        "row_count_valid = MIN_ROW_COUNT <= total_rows <= MAX_ROW_COUNT\n",
        "add_validation_result(\n",
        "    check_name=\"Row Count Range\",\n",
        "    check_type=\"completeness\",\n",
        "    column_name=\"*\",\n",
        "    passed=row_count_valid,\n",
        "    invalid_count=0 if row_count_valid else total_rows,\n",
        "    threshold=f\"{MIN_ROW_COUNT}-{MAX_ROW_COUNT}\",\n",
        "    message=f\"Row count {total_rows:,} is {'within' if row_count_valid else 'outside'} expected range\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 2: Primary key uniqueness (critical for master data)\n",
        "duplicate_count = total_rows - distinct_products\n",
        "duplicate_pct = (duplicate_count / total_rows * 100) if total_rows > 0 else 0\n",
        "pk_valid = duplicate_pct <= MAX_DUPLICATE_PCT\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Primary Key Uniqueness\",\n",
        "    check_type=\"uniqueness\",\n",
        "    column_name=PK_COLUMN,\n",
        "    passed=pk_valid,\n",
        "    invalid_count=duplicate_count,\n",
        "    threshold=f\"<={MAX_DUPLICATE_PCT}%\",\n",
        "    message=f\"Found {duplicate_count:,} duplicates ({duplicate_pct:.2f}%)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 3: Null value checks for critical columns\n",
        "critical_columns = [PK_COLUMN, \"created_at\", \"product_name\"]\n",
        "\n",
        "for col_name in critical_columns:\n",
        "    null_count = df.filter(col(col_name).isNull()).count()\n",
        "    null_valid = null_count == 0\n",
        "    \n",
        "    add_validation_result(\n",
        "        check_name=f\"Null Check - {col_name}\",\n",
        "        check_type=\"completeness\",\n",
        "        column_name=col_name,\n",
        "        passed=null_valid,\n",
        "        invalid_count=null_count,\n",
        "        threshold=\"0\",\n",
        "        message=f\"Found {null_count:,} null values\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 4: Positive product IDs\n",
        "negative_ids = df.filter(col(PK_COLUMN) <= 0).count()\n",
        "id_valid = negative_ids == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Positive Integer - product_id\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=PK_COLUMN,\n",
        "    passed=id_valid,\n",
        "    invalid_count=negative_ids,\n",
        "    threshold=\">0\",\n",
        "    message=f\"Found {negative_ids:,} non-positive IDs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 5: No future dates\n",
        "current_timestamp = datetime.now()\n",
        "future_dates = df.filter(col(\"created_at\") > lit(current_timestamp)).count()\n",
        "date_valid = future_dates == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"No Future Dates\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=\"created_at\",\n",
        "    passed=date_valid,\n",
        "    invalid_count=future_dates,\n",
        "    threshold=\"<= current_date\",\n",
        "    message=f\"Found {future_dates:,} future dates\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 6: Valid product name format (non-empty, reasonable length)\n",
        "invalid_names = df.filter(\n",
        "    (col(\"product_name\").isNull()) | \n",
        "    (trim(col(\"product_name\")) == \"\") |\n",
        "    (length(col(\"product_name\")) < 2) |\n",
        "    (length(col(\"product_name\")) > 100)\n",
        ").count()\n",
        "name_valid = invalid_names == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Valid Product Name\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=\"product_name\",\n",
        "    passed=name_valid,\n",
        "    invalid_count=invalid_names,\n",
        "    threshold=\"2-100 characters\",\n",
        "    message=f\"Found {invalid_names:,} invalid product names\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 7: Product name uniqueness (business logic)\n",
        "duplicate_names = total_rows - distinct_names\n",
        "name_unique = duplicate_names == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Product Name Uniqueness\",\n",
        "    check_type=\"uniqueness\",\n",
        "    column_name=\"product_name\",\n",
        "    passed=name_unique,\n",
        "    invalid_count=duplicate_names,\n",
        "    threshold=\"0 duplicates\",\n",
        "    message=f\"Found {duplicate_names:,} duplicate product names\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Calculate Quality Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate overall quality score\n",
        "total_checks = len(validation_results)\n",
        "passed_checks = sum([1 for r in validation_results if r[\"passed\"] == \"True\"])\n",
        "quality_score = (passed_checks / total_checks * 100) if total_checks > 0 else 0\n",
        "overall_status = \"PASSED\" if quality_score == 100 else \"FAILED\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"QUALITY SCORE: {quality_score:.1f}%\")\n",
        "print(f\"CHECKS PASSED: {passed_checks}/{total_checks}\")\n",
        "print(f\"OVERALL STATUS: {overall_status}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Persist Results to Quality Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create validation log DataFrame with exact schema matching table\n",
        "log_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"check_name\", StringType(), False),\n",
        "    StructField(\"check_type\", StringType(), False),\n",
        "    StructField(\"column_name\", StringType(), True),\n",
        "    StructField(\"passed\", StringType(), False),\n",
        "    StructField(\"invalid_count\", IntegerType(), False),\n",
        "    StructField(\"threshold\", StringType(), True),\n",
        "    StructField(\"message\", StringType(), True)\n",
        "])\n",
        "\n",
        "validation_log_df = spark.createDataFrame(validation_results, schema=log_schema)\n",
        "\n",
        "# Write to quality log table (append mode)\n",
        "validation_log_df.write.mode(\"append\").saveAsTable(QUALITY_LOG_TABLE)\n",
        "\n",
        "print(f\"✓ Validation results written to {QUALITY_LOG_TABLE}\")\n",
        "print(f\"  Records written: {len(validation_results)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Persist Summary to Quality Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate null violations\n",
        "null_violations = sum([r[\"invalid_count\"] for r in validation_results if r[\"check_type\"] == \"completeness\" and \"Null Check\" in r[\"check_name\"]])\n",
        "\n",
        "# Create summary record\n",
        "summary_data = [{\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"run_timestamp\": RUN_TIMESTAMP,\n",
        "    \"table_name\": SOURCE_TABLE,\n",
        "    \"row_count\": total_rows,\n",
        "    \"pk_duplicate_count\": duplicate_count,\n",
        "    \"null_violations\": null_violations,\n",
        "    \"validation_checks_total\": total_checks,\n",
        "    \"validation_checks_passed\": passed_checks,\n",
        "    \"quality_score\": f\"{quality_score:.1f}\",\n",
        "    \"overall_status\": overall_status\n",
        "}]\n",
        "\n",
        "summary_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"row_count\", IntegerType(), False),\n",
        "    StructField(\"pk_duplicate_count\", IntegerType(), False),\n",
        "    StructField(\"null_violations\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_total\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_passed\", IntegerType(), False),\n",
        "    StructField(\"quality_score\", StringType(), False),\n",
        "    StructField(\"overall_status\", StringType(), False)\n",
        "])\n",
        "\n",
        "summary_df = spark.createDataFrame(summary_data, schema=summary_schema)\n",
        "\n",
        "# Write to summary table (append mode)\n",
        "summary_df.write.mode(\"append\").saveAsTable(QUALITY_SUMMARY_TABLE)\n",
        "\n",
        "print(f\"✓ Summary written to {QUALITY_SUMMARY_TABLE}\")\n",
        "print(f\"\\nValidation Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Verification - Query Persisted Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query and display persisted log results for this run\n",
        "print(\"Validation Log Records:\")\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT check_name, check_type, column_name, passed, invalid_count, message\n",
        "    FROM {QUALITY_LOG_TABLE}\n",
        "    WHERE run_id = '{RUN_ID}'\n",
        "    ORDER BY check_name\n",
        "\"\"\").show(truncate=False)\n",
        "\n",
        "# Query and display summary\n",
        "print(\"\\nQuality Summary:\")\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT table_name, row_count, pk_duplicate_count, null_violations,\n",
        "           validation_checks_passed, validation_checks_total, \n",
        "           quality_score, overall_status\n",
        "    FROM {QUALITY_SUMMARY_TABLE}\n",
        "    WHERE run_id = '{RUN_ID}'\n",
        "\"\"\").show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}