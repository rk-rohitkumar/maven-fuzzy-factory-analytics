{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Quality Validation - Order Items Table\n",
        "\n",
        "**Table:** `stg_order_items`  \n",
        "**Project:** Maven Fuzzy Factory E-Commerce Analytics  \n",
        "**Created:** November 20, 2025  \n",
        "**Purpose:** Validate data quality for order items staging table\n",
        "\n",
        "---\n",
        "\n",
        "## Validation Scope\n",
        "\n",
        "**Primary Key:** order_item_id  \n",
        "**Foreign Keys:** order_id, product_id  \n",
        "**Critical Fields:** created_at, is_primary_item, price_usd, cogs_usd  \n",
        "**Expected Row Count Range:** 1,000 - 2,000,000\n",
        "\n",
        "**Validation Checks:**\n",
        "- Row count within expected range\n",
        "- Primary key uniqueness\n",
        "- Null checks on critical columns\n",
        "- Data type validation\n",
        "- Positive values for IDs and financial fields\n",
        "- Binary flag validation (is_primary_item)\n",
        "- No future dates\n",
        "- Business logic: price >= cogs (no negative margins)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import IntegerType, StructType, StructField, StringType, TimestampType\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "\n",
        "# Restore Python built-in sum (prevent PySpark function shadowing)\n",
        "del sum\n",
        "\n",
        "# Configuration\n",
        "SOURCE_TABLE = \"stg_order_items\"\n",
        "PK_COLUMN = \"order_item_id\"\n",
        "QUALITY_LOG_TABLE = \"data_quality_log\"\n",
        "QUALITY_SUMMARY_TABLE = \"data_quality_summary\"\n",
        "\n",
        "# Quality thresholds\n",
        "MAX_DUPLICATE_PCT = 1.0  # Max 1% duplicates allowed\n",
        "MIN_ROW_COUNT = 1000\n",
        "MAX_ROW_COUNT = 2000000\n",
        "\n",
        "# Validation run metadata\n",
        "RUN_ID = str(uuid.uuid4())\n",
        "RUN_TIMESTAMP = datetime.now()\n",
        "\n",
        "print(f\"Validation Run ID: {RUN_ID}\")\n",
        "print(f\"Run Timestamp: {RUN_TIMESTAMP}\")\n",
        "print(f\"Source Table: {SOURCE_TABLE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Source Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load staging table\n",
        "df = spark.read.table(SOURCE_TABLE)\n",
        "\n",
        "print(f\"Total Rows: {df.count():,}\")\n",
        "print(f\"Total Columns: {len(df.columns)}\")\n",
        "print(\"\\nSchema:\")\n",
        "df.printSchema()\n",
        "\n",
        "# Display sample\n",
        "print(\"\\nSample Data:\")\n",
        "df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "total_rows = df.count()\n",
        "distinct_items = df.select(PK_COLUMN).distinct().count()\n",
        "distinct_orders = df.select(\"order_id\").distinct().count()\n",
        "distinct_products = df.select(\"product_id\").distinct().count()\n",
        "\n",
        "# Date range\n",
        "date_stats = df.select(\n",
        "    min(col(\"created_at\")).alias(\"min_date\"),\n",
        "    max(col(\"created_at\")).alias(\"max_date\")\n",
        ").collect()[0]\n",
        "\n",
        "# Primary item analysis\n",
        "primary_item_stats = df.groupBy(\"is_primary_item\").count().orderBy(\"is_primary_item\")\n",
        "\n",
        "# Revenue statistics\n",
        "revenue_stats = df.select(\n",
        "    sum(col(\"price_usd\")).alias(\"total_revenue\"),\n",
        "    avg(col(\"price_usd\")).alias(\"avg_item_price\"),\n",
        "    sum(col(\"cogs_usd\")).alias(\"total_cogs\"),\n",
        "    sum(col(\"price_usd\") - col(\"cogs_usd\")).alias(\"total_margin\")\n",
        ").collect()[0]\n",
        "\n",
        "# Product popularity\n",
        "product_stats = df.groupBy(\"product_id\").count().orderBy(desc(\"count\"))\n",
        "\n",
        "print(f\"Total Rows: {total_rows:,}\")\n",
        "print(f\"Distinct Order Items: {distinct_items:,}\")\n",
        "print(f\"Distinct Orders: {distinct_orders:,}\")\n",
        "print(f\"Distinct Products: {distinct_products:,}\")\n",
        "print(f\"Duplicate Items: {total_rows - distinct_items:,} ({((total_rows - distinct_items) / total_rows * 100):.2f}%)\")\n",
        "print(f\"Date Range: {date_stats['min_date']} to {date_stats['max_date']}\")\n",
        "print(f\"\\nPrimary Item Distribution:\")\n",
        "primary_item_stats.show()\n",
        "print(f\"\\nRevenue Metrics:\")\n",
        "print(f\"  Total Revenue: ${revenue_stats['total_revenue']:,.2f}\")\n",
        "print(f\"  Average Item Price: ${revenue_stats['avg_item_price']:.2f}\")\n",
        "print(f\"  Total COGS: ${revenue_stats['total_cogs']:,.2f}\")\n",
        "print(f\"  Total Margin: ${revenue_stats['total_margin']:,.2f}\")\n",
        "print(f\"\\nTop 5 Products by Volume:\")\n",
        "product_stats.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Validation Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize validation results storage\n",
        "validation_results = []\n",
        "\n",
        "def add_validation_result(check_name, check_type, column_name, passed, invalid_count, threshold, message):\n",
        "    \"\"\"Helper function to store validation results\"\"\"\n",
        "    validation_results.append({\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"run_timestamp\": RUN_TIMESTAMP,\n",
        "        \"table_name\": SOURCE_TABLE,\n",
        "        \"check_name\": check_name,\n",
        "        \"check_type\": check_type,\n",
        "        \"column_name\": column_name,\n",
        "        \"passed\": \"True\" if passed else \"False\",\n",
        "        \"invalid_count\": invalid_count,\n",
        "        \"threshold\": threshold,\n",
        "        \"message\": message\n",
        "    })\n",
        "    \n",
        "    status = \"✓ PASSED\" if passed else \"✗ FAILED\"\n",
        "    print(f\"{status} - {check_name}: {message}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 1: Row count within expected range\n",
        "row_count_valid = MIN_ROW_COUNT <= total_rows <= MAX_ROW_COUNT\n",
        "add_validation_result(\n",
        "    check_name=\"Row Count Range\",\n",
        "    check_type=\"completeness\",\n",
        "    column_name=\"*\",\n",
        "    passed=row_count_valid,\n",
        "    invalid_count=0 if row_count_valid else total_rows,\n",
        "    threshold=f\"{MIN_ROW_COUNT}-{MAX_ROW_COUNT}\",\n",
        "    message=f\"Row count {total_rows:,} is {'within' if row_count_valid else 'outside'} expected range\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 2: Primary key uniqueness\n",
        "duplicate_count = total_rows - distinct_items\n",
        "duplicate_pct = (duplicate_count / total_rows * 100) if total_rows > 0 else 0\n",
        "pk_valid = duplicate_pct <= MAX_DUPLICATE_PCT\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Primary Key Uniqueness\",\n",
        "    check_type=\"uniqueness\",\n",
        "    column_name=PK_COLUMN,\n",
        "    passed=pk_valid,\n",
        "    invalid_count=duplicate_count,\n",
        "    threshold=f\"<={MAX_DUPLICATE_PCT}%\",\n",
        "    message=f\"Found {duplicate_count:,} duplicates ({duplicate_pct:.2f}%)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 3: Null value checks for critical columns\n",
        "critical_columns = [PK_COLUMN, \"created_at\", \"order_id\", \"product_id\", \"is_primary_item\", \"price_usd\", \"cogs_usd\"]\n",
        "\n",
        "for col_name in critical_columns:\n",
        "    null_count = df.filter(col(col_name).isNull()).count()\n",
        "    null_valid = null_count == 0\n",
        "    \n",
        "    add_validation_result(\n",
        "        check_name=f\"Null Check - {col_name}\",\n",
        "        check_type=\"completeness\",\n",
        "        column_name=col_name,\n",
        "        passed=null_valid,\n",
        "        invalid_count=null_count,\n",
        "        threshold=\"0\",\n",
        "        message=f\"Found {null_count:,} null values\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 4: Positive values for IDs and financial fields\n",
        "numeric_checks = {\n",
        "    PK_COLUMN: \">0\",\n",
        "    \"order_id\": \">0\",\n",
        "    \"product_id\": \">0\",\n",
        "    \"price_usd\": \">0\",\n",
        "    \"cogs_usd\": \">0\"\n",
        "}\n",
        "\n",
        "for col_name, threshold in numeric_checks.items():\n",
        "    invalid_count = df.filter(col(col_name) <= 0).count()\n",
        "    valid = invalid_count == 0\n",
        "    \n",
        "    add_validation_result(\n",
        "        check_name=f\"Positive Value - {col_name}\",\n",
        "        check_type=\"validity\",\n",
        "        column_name=col_name,\n",
        "        passed=valid,\n",
        "        invalid_count=invalid_count,\n",
        "        threshold=threshold,\n",
        "        message=f\"Found {invalid_count:,} non-positive values\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 5: Binary flag validation (is_primary_item)\n",
        "invalid_flags = df.filter(~col(\"is_primary_item\").isin([0, 1])).count()\n",
        "flag_valid = invalid_flags == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Binary Flag - is_primary_item\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=\"is_primary_item\",\n",
        "    passed=flag_valid,\n",
        "    invalid_count=invalid_flags,\n",
        "    threshold=\"0 or 1\",\n",
        "    message=f\"Found {invalid_flags:,} invalid binary values\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 6: No future dates\n",
        "current_timestamp = datetime.now()\n",
        "future_dates = df.filter(col(\"created_at\") > lit(current_timestamp)).count()\n",
        "date_valid = future_dates == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"No Future Dates\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=\"created_at\",\n",
        "    passed=date_valid,\n",
        "    invalid_count=future_dates,\n",
        "    threshold=\"<= current_date\",\n",
        "    message=f\"Found {future_dates:,} future dates\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check 7: Business logic - price >= cogs\n",
        "negative_margin = df.filter(col(\"price_usd\") < col(\"cogs_usd\")).count()\n",
        "margin_valid = negative_margin == 0\n",
        "\n",
        "add_validation_result(\n",
        "    check_name=\"Business Logic - Price >= COGS\",\n",
        "    check_type=\"validity\",\n",
        "    column_name=\"price_usd,cogs_usd\",\n",
        "    passed=margin_valid,\n",
        "    invalid_count=negative_margin,\n",
        "    threshold=\"price_usd >= cogs_usd\",\n",
        "    message=f\"Found {negative_margin:,} items with negative margin\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Calculate Quality Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate overall quality score\n",
        "total_checks = len(validation_results)\n",
        "passed_checks = sum([1 for r in validation_results if r[\"passed\"] == \"True\"])\n",
        "quality_score = (passed_checks / total_checks * 100) if total_checks > 0 else 0\n",
        "overall_status = \"PASSED\" if quality_score == 100 else \"FAILED\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"QUALITY SCORE: {quality_score:.1f}%\")\n",
        "print(f\"CHECKS PASSED: {passed_checks}/{total_checks}\")\n",
        "print(f\"OVERALL STATUS: {overall_status}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Persist Results to Quality Log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create validation log DataFrame with exact schema matching table\n",
        "log_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"check_name\", StringType(), False),\n",
        "    StructField(\"check_type\", StringType(), False),\n",
        "    StructField(\"column_name\", StringType(), True),\n",
        "    StructField(\"passed\", StringType(), False),\n",
        "    StructField(\"invalid_count\", IntegerType(), False),\n",
        "    StructField(\"threshold\", StringType(), True),\n",
        "    StructField(\"message\", StringType(), True)\n",
        "])\n",
        "\n",
        "validation_log_df = spark.createDataFrame(validation_results, schema=log_schema)\n",
        "\n",
        "# Write to quality log table (append mode)\n",
        "validation_log_df.write.mode(\"append\").saveAsTable(QUALITY_LOG_TABLE)\n",
        "\n",
        "print(f\"✓ Validation results written to {QUALITY_LOG_TABLE}\")\n",
        "print(f\"  Records written: {len(validation_results)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Persist Summary to Quality Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate null violations\n",
        "null_violations = sum([r[\"invalid_count\"] for r in validation_results if r[\"check_type\"] == \"completeness\" and \"Null Check\" in r[\"check_name\"]])\n",
        "\n",
        "# Create summary record\n",
        "summary_data = [{\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"run_timestamp\": RUN_TIMESTAMP,\n",
        "    \"table_name\": SOURCE_TABLE,\n",
        "    \"row_count\": total_rows,\n",
        "    \"pk_duplicate_count\": duplicate_count,\n",
        "    \"null_violations\": null_violations,\n",
        "    \"validation_checks_total\": total_checks,\n",
        "    \"validation_checks_passed\": passed_checks,\n",
        "    \"quality_score\": f\"{quality_score:.1f}\",\n",
        "    \"overall_status\": overall_status\n",
        "}]\n",
        "\n",
        "summary_schema = StructType([\n",
        "    StructField(\"run_id\", StringType(), False),\n",
        "    StructField(\"run_timestamp\", TimestampType(), False),\n",
        "    StructField(\"table_name\", StringType(), False),\n",
        "    StructField(\"row_count\", IntegerType(), False),\n",
        "    StructField(\"pk_duplicate_count\", IntegerType(), False),\n",
        "    StructField(\"null_violations\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_total\", IntegerType(), False),\n",
        "    StructField(\"validation_checks_passed\", IntegerType(), False),\n",
        "    StructField(\"quality_score\", StringType(), False),\n",
        "    StructField(\"overall_status\", StringType(), False)\n",
        "])\n",
        "\n",
        "summary_df = spark.createDataFrame(summary_data, schema=summary_schema)\n",
        "\n",
        "# Write to summary table (append mode)\n",
        "summary_df.write.mode(\"append\").saveAsTable(QUALITY_SUMMARY_TABLE)\n",
        "\n",
        "print(f\"✓ Summary written to {QUALITY_SUMMARY_TABLE}\")\n",
        "print(f\"\\nValidation Complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Verification - Query Persisted Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query and display persisted log results for this run\n",
        "print(\"Validation Log Records:\")\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT check_name, check_type, column_name, passed, invalid_count, message\n",
        "    FROM {QUALITY_LOG_TABLE}\n",
        "    WHERE run_id = '{RUN_ID}'\n",
        "    ORDER BY check_name\n",
        "\"\"\").show(truncate=False)\n",
        "\n",
        "# Query and display summary\n",
        "print(\"\\nQuality Summary:\")\n",
        "spark.sql(f\"\"\"\n",
        "    SELECT table_name, row_count, pk_duplicate_count, null_violations,\n",
        "           validation_checks_passed, validation_checks_total, \n",
        "           quality_score, overall_status\n",
        "    FROM {QUALITY_SUMMARY_TABLE}\n",
        "    WHERE run_id = '{RUN_ID}'\n",
        "\"\"\").show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}